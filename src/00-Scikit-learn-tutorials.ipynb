{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from pprint import pprint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DESCR': 'Optical Recognition of Handwritten Digits Data Set\\n'\n",
      "          '===================================================\\n'\n",
      "          '\\n'\n",
      "          'Notes\\n'\n",
      "          '-----\\n'\n",
      "          'Data Set Characteristics:\\n'\n",
      "          '    :Number of Instances: 5620\\n'\n",
      "          '    :Number of Attributes: 64\\n'\n",
      "          '    :Attribute Information: 8x8 image of integer pixels in the '\n",
      "          'range 0..16.\\n'\n",
      "          '    :Missing Attribute Values: None\\n'\n",
      "          \"    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\\n\"\n",
      "          '    :Date: July; 1998\\n'\n",
      "          '\\n'\n",
      "          'This is a copy of the test set of the UCI ML hand-written digits '\n",
      "          'datasets\\n'\n",
      "          'http://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\\n'\n",
      "          '\\n'\n",
      "          'The data set contains images of hand-written digits: 10 classes '\n",
      "          'where\\n'\n",
      "          'each class refers to a digit.\\n'\n",
      "          '\\n'\n",
      "          'Preprocessing programs made available by NIST were used to extract\\n'\n",
      "          'normalized bitmaps of handwritten digits from a preprinted form. '\n",
      "          'From a\\n'\n",
      "          'total of 43 people, 30 contributed to the training set and '\n",
      "          'different 13\\n'\n",
      "          'to the test set. 32x32 bitmaps are divided into nonoverlapping '\n",
      "          'blocks of\\n'\n",
      "          '4x4 and the number of on pixels are counted in each block. This '\n",
      "          'generates\\n'\n",
      "          'an input matrix of 8x8 where each element is an integer in the '\n",
      "          'range\\n'\n",
      "          '0..16. This reduces dimensionality and gives invariance to small\\n'\n",
      "          'distortions.\\n'\n",
      "          '\\n'\n",
      "          'For info on NIST preprocessing routines, see M. D. Garris, J. L. '\n",
      "          'Blue, G.\\n'\n",
      "          'T. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, '\n",
      "          'and C.\\n'\n",
      "          'L. Wilson, NIST Form-Based Handprint Recognition System, NISTIR '\n",
      "          '5469,\\n'\n",
      "          '1994.\\n'\n",
      "          '\\n'\n",
      "          'References\\n'\n",
      "          '----------\\n'\n",
      "          '  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and '\n",
      "          'Their\\n'\n",
      "          '    Applications to Handwritten Digit Recognition, MSc Thesis, '\n",
      "          'Institute of\\n'\n",
      "          '    Graduate Studies in Science and Engineering, Bogazici '\n",
      "          'University.\\n'\n",
      "          '  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, '\n",
      "          'Kybernetika.\\n'\n",
      "          '  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai '\n",
      "          'Qin.\\n'\n",
      "          '    Linear dimensionalityreduction using relevance weighted LDA. '\n",
      "          'School of\\n'\n",
      "          '    Electrical and Electronic Engineering Nanyang Technological '\n",
      "          'University.\\n'\n",
      "          '    2005.\\n'\n",
      "          '  - Claudio Gentile. A New Approximate Maximal Margin '\n",
      "          'Classification\\n'\n",
      "          '    Algorithm. NIPS. 2000.\\n',\n",
      " 'data': array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0., ..., 10.,  0.,  0.],\n",
      "       [ 0.,  0.,  0., ..., 16.,  9.,  0.],\n",
      "       ...,\n",
      "       [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
      "       [ 0.,  0.,  2., ..., 12.,  0.,  0.],\n",
      "       [ 0.,  0., 10., ..., 12.,  1.,  0.]]),\n",
      " 'images': array([[[ 0.,  0.,  5., ...,  1.,  0.,  0.],\n",
      "        [ 0.,  0., 13., ..., 15.,  5.,  0.],\n",
      "        [ 0.,  3., 15., ..., 11.,  8.,  0.],\n",
      "        ...,\n",
      "        [ 0.,  4., 11., ..., 12.,  7.,  0.],\n",
      "        [ 0.,  2., 14., ..., 12.,  0.,  0.],\n",
      "        [ 0.,  0.,  6., ...,  0.,  0.,  0.]],\n",
      "\n",
      "       [[ 0.,  0.,  0., ...,  5.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., ...,  9.,  0.,  0.],\n",
      "        [ 0.,  0.,  3., ...,  6.,  0.,  0.],\n",
      "        ...,\n",
      "        [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
      "        [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., ..., 10.,  0.,  0.]],\n",
      "\n",
      "       [[ 0.,  0.,  0., ..., 12.,  0.,  0.],\n",
      "        [ 0.,  0.,  3., ..., 14.,  0.,  0.],\n",
      "        [ 0.,  0.,  8., ..., 16.,  0.,  0.],\n",
      "        ...,\n",
      "        [ 0.,  9., 16., ...,  0.,  0.,  0.],\n",
      "        [ 0.,  3., 13., ..., 11.,  5.,  0.],\n",
      "        [ 0.,  0.,  0., ..., 16.,  9.,  0.]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 0.,  0.,  1., ...,  1.,  0.,  0.],\n",
      "        [ 0.,  0., 13., ...,  2.,  1.,  0.],\n",
      "        [ 0.,  0., 16., ..., 16.,  5.,  0.],\n",
      "        ...,\n",
      "        [ 0.,  0., 16., ..., 15.,  0.,  0.],\n",
      "        [ 0.,  0., 15., ..., 16.,  0.,  0.],\n",
      "        [ 0.,  0.,  2., ...,  6.,  0.,  0.]],\n",
      "\n",
      "       [[ 0.,  0.,  2., ...,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 14., ..., 15.,  1.,  0.],\n",
      "        [ 0.,  4., 16., ..., 16.,  7.,  0.],\n",
      "        ...,\n",
      "        [ 0.,  0.,  0., ..., 16.,  2.,  0.],\n",
      "        [ 0.,  0.,  4., ..., 16.,  2.,  0.],\n",
      "        [ 0.,  0.,  5., ..., 12.,  0.,  0.]],\n",
      "\n",
      "       [[ 0.,  0., 10., ...,  1.,  0.,  0.],\n",
      "        [ 0.,  2., 16., ...,  1.,  0.,  0.],\n",
      "        [ 0.,  0., 15., ..., 15.,  0.,  0.],\n",
      "        ...,\n",
      "        [ 0.,  4., 16., ..., 16.,  6.,  0.],\n",
      "        [ 0.,  8., 16., ..., 16.,  8.,  0.],\n",
      "        [ 0.,  1.,  8., ..., 12.,  1.,  0.]]]),\n",
      " 'target': array([0, 1, 2, ..., 8, 9, 8]),\n",
      " 'target_names': array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])}\n"
     ]
    }
   ],
   "source": [
    "iris=datasets.load_iris()\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "pprint(digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0., ..., 10.,  0.,  0.],\n",
      "       [ 0.,  0.,  0., ..., 16.,  9.,  0.],\n",
      "       ...,\n",
      "       [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
      "       [ 0.,  0.,  2., ..., 12.,  0.,  0.],\n",
      "       [ 0.,  0., 10., ..., 12.,  1.,  0.]])\n",
      "array([0, 1, 2, ..., 8, 9, 8])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  5., 13.,  9.,  1.,  0.,  0.],\n",
       "       [ 0.,  0., 13., 15., 10., 15.,  5.,  0.],\n",
       "       [ 0.,  3., 15.,  2.,  0., 11.,  8.,  0.],\n",
       "       [ 0.,  4., 12.,  0.,  0.,  8.,  8.,  0.],\n",
       "       [ 0.,  5.,  8.,  0.,  0.,  9.,  8.,  0.],\n",
       "       [ 0.,  4., 11.,  0.,  1., 12.,  7.,  0.],\n",
       "       [ 0.,  2., 14.,  5., 10., 12.,  0.,  0.],\n",
       "       [ 0.,  0.,  6., 13., 10.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pprint(digits.data)\n",
    "pprint(digits.target)\n",
    "digits.images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading 20news dataset. This may take a few minutes.\n",
      "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
     ]
    }
   ],
   "source": [
    "categories = ['alt.atheism', 'soc.religion.christian',\n",
    "              'comp.graphics', 'sci.med']\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "twenty_train = fetch_20newsgroups(subset='train',\n",
    "    categories=categories, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.utils.Bunch'>\n",
      "['alt.atheism', 'comp.graphics', 'sci.med', 'soc.religion.christian']\n",
      "2257\n",
      "2257\n",
      "From: sd345@city.ac.uk (Michael Collier)\n",
      "Subject: Converting images to HP LaserJet III?\n",
      "Nntp-Posting-Host: hampton\n",
      "comp.graphics\n",
      "[1 1 3 3 3 3 3 2 2 2]\n",
      "comp.graphics\n",
      "comp.graphics\n",
      "soc.religion.christian\n",
      "soc.religion.christian\n",
      "soc.religion.christian\n",
      "soc.religion.christian\n",
      "soc.religion.christian\n",
      "sci.med\n",
      "sci.med\n",
      "sci.med\n"
     ]
    }
   ],
   "source": [
    "print(type(twenty_train))\n",
    "print(twenty_train.target_names)\n",
    "print(len(twenty_train.data))\n",
    "print(len(twenty_train.filenames))\n",
    "print(\"\\n\".join(twenty_train.data[0].split(\"\\n\")[:3]))\n",
    "print(twenty_train.target_names[twenty_train.target[0]])\n",
    "# classes are folder names, but stored the index to the name\n",
    "print(twenty_train.target[:10])\n",
    "for t in twenty_train.target[:10]:\n",
    "    print(twenty_train.target_names[t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting features\n",
    "\n",
    "# Bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import cross_val_predict\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "words = [feature_map(w) for w in data[\"Word\"].values.tolist()]\n",
    "tags = data[\"Tag\"].values.tolist()\n",
    "pred = cross_val_predict(RandomForestClassifier(n_estimators=20),\n",
    "                         X=words, y=tags, cv=5)\n",
    "report = classification_report(y_pred=pred, y_true=tags)\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ahltmai",
   "language": "python",
   "name": "ahltmai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
