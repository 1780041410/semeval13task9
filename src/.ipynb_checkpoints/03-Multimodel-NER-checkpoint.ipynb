{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pau/anaconda3/envs/ahltmai/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xx0x0X_x0\n",
      "Xx0x0Xx0\n",
      "Xx0x_0X_x0\n"
     ]
    }
   ],
   "source": [
    "from CustomFeatures import MyFeatures\n",
    "from NERmodel import NERmodel\n",
    "import subprocess\n",
    "import traceback, sys\n",
    "import pickle\n",
    "\n",
    "mf = MyFeatures()\n",
    "print(mf.wordStructure((\"Hell75o3,HA-niacidine0\",)))\n",
    "print(mf.wordStructure2((\"Hell75o3,HA-niacidine0\",)))\n",
    "print(mf.wordStructure((\"Hell75o_3,HA-niacidine0\",)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pau/anaconda3/envs/ahltmai/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature instances:\n",
      "[<CustomFeatures.MyFeatures object at 0x7fe0105e6518>, <CustomFeatures.MyFeatures object at 0x7fdfcccb20f0>, <CustomFeatures.MyFeatures object at 0x7fdfccd16dd8>, <CustomFeatures.MyFeatures object at 0x7fdfcbfb5240>, <CustomFeatures.MyFeatures object at 0x7fdfcbfb5390>, <CustomFeatures.MyFeatures object at 0x7fdfcbfb54e0>, <CustomFeatures.MyFeatures object at 0x7fdfcbfb5630>, <CustomFeatures.MyFeatures object at 0x7fdfcbfb5780>]\n",
      "\n",
      "models:\n",
      "[<NERmodel.NERmodel object at 0x7fdfcbfb5908>, <NERmodel.NERmodel object at 0x7fdfcbfb5b00>, <NERmodel.NERmodel object at 0x7fdfcbfb5a90>, <NERmodel.NERmodel object at 0x7fdfcbfb5b38>, <NERmodel.NERmodel object at 0x7fdfcbfb5978>, <NERmodel.NERmodel object at 0x7fdfcbfb5e10>, <NERmodel.NERmodel object at 0x7fdfcbfb5f98>, <NERmodel.NERmodel object at 0x7fdfcbd0e160>]\n",
      "\n",
      "8\n",
      "[None, None, None, None, None, None, None, None]\n",
      "model pickles:\n",
      "['../data/models/svm-pipeline_20180515215541.pkl', '../data/models/svm-pipeline_20180515222454.pkl', '../data/models/svm-pipeline_20180515230240.pkl', '../data/models/svm-pipeline_20180515233919.pkl', '../data/models/svm-pipeline_20180516000217.pkl', '../data/models/svm-pipeline_20180516004350.pkl', '../data/models/svm-pipeline_20180516011533.pkl', '../data/models/svm-pipeline_20180516014303.pkl']\n",
      "\n",
      "model 0:\n",
      "0.3190789473684211 \n",
      "model 1:\n",
      "0.27960526315789475 \n",
      "model 2:\n",
      "0.5263157894736842 \n",
      "model 3:\n",
      "0.27631578947368424 \n",
      "model 4:\n",
      "0.3125 \n",
      "model 5:\n",
      "0.26973684210526316 \n",
      "model 6:\n",
      "0.3125 \n",
      "model 7:\n",
      "0.29605263157894735 \n"
     ]
    }
   ],
   "source": [
    "# generate feature subsets\n",
    "from CustomFeatures import MyFeatures\n",
    "from NERmodel import NERmodel\n",
    "import subprocess\n",
    "import traceback, sys\n",
    "import pickle\n",
    "\n",
    "\n",
    "# name the batch training\n",
    "training_set_name = \"singleton20180516\"\n",
    "\n",
    "# preapre different MyFeature instances\n",
    "fs = []\n",
    "# number of model permutations\n",
    "m = 1\n",
    "# original model with all features\n",
    "mf = MyFeatures()\n",
    "fs.append(mf)\n",
    "# for now it is random shuffling, but this is gonna be a manual selection of features\n",
    "for i in range(m):\n",
    "    try:\n",
    "        mf = MyFeatures()\n",
    "        mf.deriveNewFeatureSet(degree=3)\n",
    "        fs.append(mf)\n",
    "        #mf.printActiveFeatureFunctions()\n",
    "        #print()\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "print(\"feature instances:\")\n",
    "print(fs)\n",
    "print()    \n",
    "\n",
    "# initialize\n",
    "models=[]\n",
    "for fset in fs:\n",
    "    try:\n",
    "        model = NERmodel(featureset=fset)\n",
    "        model.setName(training_set_name)\n",
    "        models.append(model)\n",
    "    except:\n",
    "        pass\n",
    "print(\"models:\")\n",
    "print(models)\n",
    "print()\n",
    "    \n",
    "\n",
    "# train all models\n",
    "models_pickles =[None]*len(models)\n",
    "print(len(models_pickles))\n",
    "print(models_pickles)\n",
    "for i in range(len(models)):\n",
    "    model = models[i]\n",
    "    try:\n",
    "        model.trainFeatureExtraction(\"../data/LaboCase/Train\", limit=None)\n",
    "        model.saveTrainingFeatures(\"../data/models/multitrain-data\"+str(i)+\".json\")\n",
    "        model.newModelPipeline()\n",
    "        models_pickles[i] = model.saveModelPipeline()\n",
    "    except Exception:\n",
    "        print(\"Exception in user code:\",i)\n",
    "        print(\"-\"*60)\n",
    "        traceback.print_exc(file=sys.stdout)\n",
    "        print(\"-\"*60)\n",
    "        print(\"model \"+str(i)+\" has failed... \")\n",
    "        models_pickles[i] = None\n",
    "        \n",
    "print(\"model pickles:\")\n",
    "print(models_pickles)\n",
    "print()\n",
    "\n",
    "# test all models\n",
    "# PROBLEM I need the same feature set! so maybe the \n",
    "# pipeline should be pickled with the featureset\n",
    "# so maybe we should use pickle of the whole NER?\n",
    "results_files = [None]*len(models)\n",
    "evaluation_files = [None]*len(models)\n",
    "for i in range(len(models_pickles)):\n",
    "    modelfile = models_pickles[i]\n",
    "    fset = fs[i]\n",
    "    try:\n",
    "        model = NERmodel(featureset=fs[i])\n",
    "        model.loadModelPipeline(filepath=modelfile)\n",
    "        model.testFeatureExtraction(\n",
    "            '../data/LaboCase/Test/Test for DrugNER task/DrugBank', \n",
    "            limit=None)\n",
    "        model.predict()\n",
    "        model.parsePredictionOutput('../data/models/task9.1_'+training_set_name+'_'+str(i)+'.txt')\n",
    "        results_files[i] = '../data/models/multitrain-'+str(i)+'-output.csv'\n",
    "        print(\"model \"+str(i)+\":\")\n",
    "        evaluation_files[i] = model.autoEvaluation()\n",
    "    except  Exception:\n",
    "        print(\"Exception in user code:\",i)\n",
    "        print(\"-\"*60)\n",
    "        traceback.print_exc(file=sys.stdout)\n",
    "        print(\"-\"*60)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"model predictions:\")\n",
    "print(results_files)\n",
    "print(evaluation_files)\n",
    "print()\n",
    "\n",
    "# print all result sets\n",
    "for i in range(len(results_files)):\n",
    "    file = results_files[i]\n",
    "    file2 = evaluation_files[i]\n",
    "    print(\"model \"+ str(i)+ \"-------------------------------------------------------------------\")\n",
    "    print(open(file,'r').read())\n",
    "    print(open(file2,'r').read())\n",
    "    print(\"-------------------------------------------------------------------\")\n",
    "    print()\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ahltmai",
   "language": "python",
   "name": "ahltmai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
